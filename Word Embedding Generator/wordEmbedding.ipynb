{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product/productId</th>\n",
       "      <th>review/userId</th>\n",
       "      <th>review/profileName</th>\n",
       "      <th>review/helpfulness</th>\n",
       "      <th>review/score</th>\n",
       "      <th>review/time</th>\n",
       "      <th>review/summary</th>\n",
       "      <th>review/text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1/1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0/0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1/1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3/3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0/0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568449</th>\n",
       "      <td>B001EO7N10</td>\n",
       "      <td>A28KG5XORO54AY</td>\n",
       "      <td>Lettie D. Carter</td>\n",
       "      <td>0/0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1299628800</td>\n",
       "      <td>Will not do without</td>\n",
       "      <td>Great for sesame chicken..this is a good if no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568450</th>\n",
       "      <td>B003S1WTCU</td>\n",
       "      <td>A3I8AFVPEE8KI5</td>\n",
       "      <td>R. Sawyer</td>\n",
       "      <td>0/0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1331251200</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>I'm disappointed with the flavor. The chocolat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568451</th>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A121AA1GQV751Z</td>\n",
       "      <td>pksd \"pk_007\"</td>\n",
       "      <td>2/2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1329782400</td>\n",
       "      <td>Perfect for our maltipoo</td>\n",
       "      <td>These stars are small, so you can give 10-15 o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568452</th>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A3IBEVCTXKNOH</td>\n",
       "      <td>Kathy A. Welch \"katwel\"</td>\n",
       "      <td>1/1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1331596800</td>\n",
       "      <td>Favorite Training and reward treat</td>\n",
       "      <td>These are the BEST treats for training and rew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568453</th>\n",
       "      <td>B001LR2CU2</td>\n",
       "      <td>A3LGQPJCZVL9UC</td>\n",
       "      <td>srfell17</td>\n",
       "      <td>0/0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1338422400</td>\n",
       "      <td>Great Honey</td>\n",
       "      <td>I am very satisfied ,product is as advertised,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>568454 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       product/productId   review/userId               review/profileName  \\\n",
       "0             B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1             B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2             B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3             B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4             B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "...                  ...             ...                              ...   \n",
       "568449        B001EO7N10  A28KG5XORO54AY                 Lettie D. Carter   \n",
       "568450        B003S1WTCU  A3I8AFVPEE8KI5                        R. Sawyer   \n",
       "568451        B004I613EE  A121AA1GQV751Z                    pksd \"pk_007\"   \n",
       "568452        B004I613EE   A3IBEVCTXKNOH          Kathy A. Welch \"katwel\"   \n",
       "568453        B001LR2CU2  A3LGQPJCZVL9UC                         srfell17   \n",
       "\n",
       "       review/helpfulness review/score review/time  \\\n",
       "0                     1/1          5.0  1303862400   \n",
       "1                     0/0          1.0  1346976000   \n",
       "2                     1/1          4.0  1219017600   \n",
       "3                     3/3          2.0  1307923200   \n",
       "4                     0/0          5.0  1350777600   \n",
       "...                   ...          ...         ...   \n",
       "568449                0/0          5.0  1299628800   \n",
       "568450                0/0          2.0  1331251200   \n",
       "568451                2/2          5.0  1329782400   \n",
       "568452                1/1          5.0  1331596800   \n",
       "568453                0/0          5.0  1338422400   \n",
       "\n",
       "                            review/summary  \\\n",
       "0                    Good Quality Dog Food   \n",
       "1                        Not as Advertised   \n",
       "2                    \"Delight\" says it all   \n",
       "3                           Cough Medicine   \n",
       "4                              Great taffy   \n",
       "...                                    ...   \n",
       "568449                 Will not do without   \n",
       "568450                        disappointed   \n",
       "568451            Perfect for our maltipoo   \n",
       "568452  Favorite Training and reward treat   \n",
       "568453                         Great Honey   \n",
       "\n",
       "                                              review/text  \n",
       "0       I have bought several of the Vitality canned d...  \n",
       "1       Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2       This is a confection that has been around a fe...  \n",
       "3       If you are looking for the secret ingredient i...  \n",
       "4       Great taffy at a great price.  There was a wid...  \n",
       "...                                                   ...  \n",
       "568449  Great for sesame chicken..this is a good if no...  \n",
       "568450  I'm disappointed with the flavor. The chocolat...  \n",
       "568451  These stars are small, so you can give 10-15 o...  \n",
       "568452  These are the BEST treats for training and rew...  \n",
       "568453  I am very satisfied ,product is as advertised,...  \n",
       "\n",
       "[568454 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the path to your text document\n",
    "file_path = \"foods.txt\"\n",
    "\n",
    "# Read the text document\n",
    "with open(file_path, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Initialize lists to store data\n",
    "product_ids = []\n",
    "user_ids = []\n",
    "profile_names = []\n",
    "helpfulness = []\n",
    "scores = []\n",
    "times = []\n",
    "summaries = []\n",
    "texts = []\n",
    "\n",
    "# Iterate over the lines and extract information for each entry\n",
    "entry = {}\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    if line:\n",
    "        if \": \" in line:\n",
    "            key, value = line.split(\": \", 1)\n",
    "            entry[key] = value\n",
    "    else:\n",
    "        product_ids.append(entry.get(\"product/productId\", \"\"))\n",
    "        user_ids.append(entry.get(\"review/userId\", \"\"))\n",
    "        profile_names.append(entry.get(\"review/profileName\", \"\"))\n",
    "        helpfulness.append(entry.get(\"review/helpfulness\", \"\"))\n",
    "        scores.append(entry.get(\"review/score\", \"\"))\n",
    "        times.append(entry.get(\"review/time\", \"\"))\n",
    "        summaries.append(entry.get(\"review/summary\", \"\"))\n",
    "        texts.append(entry.get(\"review/text\", \"\"))\n",
    "        entry = {}\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "data = {\n",
    "    \"product/productId\": product_ids,\n",
    "    \"review/userId\": user_ids,\n",
    "    \"review/profileName\": profile_names,\n",
    "    \"review/helpfulness\": helpfulness,\n",
    "    \"review/score\": scores,\n",
    "    \"review/time\": times,\n",
    "    \"review/summary\": summaries,\n",
    "    \"review/text\": texts\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         I have bought several of the Vitality canned d...\n",
       "1         Product arrived labeled as Jumbo Salted Peanut...\n",
       "2         This is a confection that has been around a fe...\n",
       "3         If you are looking for the secret ingredient i...\n",
       "4         Great taffy at a great price.  There was a wid...\n",
       "                                ...                        \n",
       "568449    Great for sesame chicken..this is a good if no...\n",
       "568450    I'm disappointed with the flavor. The chocolat...\n",
       "568451    These stars are small, so you can give 10-15 o...\n",
       "568452    These are the BEST treats for training and rew...\n",
       "568453    I am very satisfied ,product is as advertised,...\n",
       "Name: review/text, Length: 568454, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewText = df[\"review/text\"]\n",
    "reviewText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load corpus\n",
    "corpus = reviewText\n",
    "sents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences prior to pre-processing:\n",
      "0    I have bought several of the Vitality canned d...\n",
      "1    Product arrived labeled as Jumbo Salted Peanut...\n",
      "2    This is a confection that has been around a fe...\n",
      "3    If you are looking for the secret ingredient i...\n",
      "4    Great taffy at a great price.  There was a wid...\n",
      "5    I got a wild hair for taffy and ordered this f...\n",
      "6    This saltwater taffy had great flavors and was...\n",
      "7    This taffy is so good.  It is very soft and ch...\n",
      "8    Right now I'm mostly just sprouting this so my...\n",
      "9    This is a very healthy dog food. Good for thei...\n",
      "Name: review/text, dtype: object\n",
      "\n",
      "Sentences after pre-processing:\n",
      "[['have', 'bought', 'several', 'of', 'the', 'vitality', 'canned', 'dog', 'food', 'products', 'and', 'have', 'found', 'them', 'all', 'to', 'be', 'of', 'good', 'quality', 'the', 'product', 'looks', 'more', 'like', 'stew', 'than', 'processed', 'meat', 'and', 'it', 'smells', 'better', 'my', 'labrador', 'is', 'finicky', 'and', 'she', 'appreciates', 'this', 'product', 'better', 'than', 'most'], ['product', 'arrived', 'labeled', 'as', 'jumbo', 'salted', 'peanuts', 'the', 'peanuts', 'were', 'actually', 'small', 'sized', 'unsalted', 'not', 'sure', 'if', 'this', 'was', 'an', 'error', 'or', 'if', 'the', 'vendor', 'intended', 'to', 'represent', 'the', 'product', 'as', 'jumbo'], ['this', 'is', 'confection', 'that', 'has', 'been', 'around', 'few', 'centuries', 'it', 'is', 'light', 'pillowy', 'citrus', 'gelatin', 'with', 'nuts', 'in', 'this', 'case', 'filberts', 'and', 'it', 'is', 'cut', 'into', 'tiny', 'squares', 'and', 'then', 'liberally', 'coated', 'with', 'powdered', 'sugar', 'and', 'it', 'is', 'tiny', 'mouthful', 'of', 'heaven', 'not', 'too', 'chewy', 'and', 'very', 'flavorful', 'highly', 'recommend', 'this', 'yummy', 'treat', 'if', 'you', 'are', 'familiar', 'with', 'the', 'story', 'of', 'lewis', 'the', 'lion', 'the', 'witch', 'and', 'the', 'wardrobe', 'this', 'is', 'the', 'treat', 'that', 'seduces', 'edmund', 'into', 'selling', 'out', 'his', 'brother', 'and', 'sisters', 'to', 'the', 'witch'], ['if', 'you', 'are', 'looking', 'for', 'the', 'secret', 'ingredient', 'in', 'robitussin', 'believe', 'have', 'found', 'it', 'got', 'this', 'in', 'addition', 'to', 'the', 'root', 'beer', 'extract', 'ordered', 'which', 'was', 'good', 'and', 'made', 'some', 'cherry', 'soda', 'the', 'flavor', 'is', 'very', 'medicinal'], ['great', 'taffy', 'at', 'great', 'price', 'there', 'was', 'wide', 'assortment', 'of', 'yummy', 'taffy', 'delivery', 'was', 'very', 'quick', 'if', 'your', 'taffy', 'lover', 'this', 'is', 'deal'], ['got', 'wild', 'hair', 'for', 'taffy', 'and', 'ordered', 'this', 'five', 'pound', 'bag', 'the', 'taffy', 'was', 'all', 'very', 'enjoyable', 'with', 'many', 'flavors', 'watermelon', 'root', 'beer', 'melon', 'peppermint', 'grape', 'etc', 'my', 'only', 'complaint', 'is', 'there', 'was', 'bit', 'too', 'much', 'red', 'black', 'licorice', 'flavored', 'pieces', 'just', 'not', 'my', 'particular', 'favorites', 'between', 'me', 'my', 'kids', 'and', 'my', 'husband', 'this', 'lasted', 'only', 'two', 'weeks', 'would', 'recommend', 'this', 'brand', 'of', 'taffy', 'it', 'was', 'delightful', 'treat'], ['this', 'saltwater', 'taffy', 'had', 'great', 'flavors', 'and', 'was', 'very', 'soft', 'and', 'chewy', 'each', 'candy', 'was', 'individually', 'wrapped', 'well', 'none', 'of', 'the', 'candies', 'were', 'stuck', 'together', 'which', 'did', 'happen', 'in', 'the', 'expensive', 'version', 'fralinger', 'would', 'highly', 'recommend', 'this', 'candy', 'served', 'it', 'at', 'beach', 'themed', 'party', 'and', 'everyone', 'loved', 'it'], ['this', 'taffy', 'is', 'so', 'good', 'it', 'is', 'very', 'soft', 'and', 'chewy', 'the', 'flavors', 'are', 'amazing', 'would', 'definitely', 'recommend', 'you', 'buying', 'it', 'very', 'satisfying'], ['right', 'now', 'mostly', 'just', 'sprouting', 'this', 'so', 'my', 'cats', 'can', 'eat', 'the', 'grass', 'they', 'love', 'it', 'rotate', 'it', 'around', 'with', 'wheatgrass', 'and', 'rye', 'too'], ['this', 'is', 'very', 'healthy', 'dog', 'food', 'good', 'for', 'their', 'digestion', 'also', 'good', 'for', 'small', 'puppies', 'my', 'dog', 'eats', 'her', 'required', 'amount', 'at', 'every', 'feeding']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentences prior to pre-processing:\")\n",
    "print(corpus[:10])\n",
    "\n",
    "# tokenising, normalising, cleaning and lowercase sentences\n",
    "for sent in corpus:\n",
    "    sents.append(gensim.utils.simple_preprocess(str(sent)))\n",
    "\n",
    "print(\"\\nSentences after pre-processing:\")\n",
    "print(sents[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "corpusName = \"amazonFoodsReview\"\n",
    "windowsCount = 10\n",
    "minCount = 2\n",
    "workersCount = 6\n",
    "\n",
    "# define Word2Vec model\n",
    "model = gensim.models.Word2Vec(\n",
    "    window=windowsCount,\n",
    "    min_count=minCount,\n",
    "    workers=workersCount\n",
    ")\n",
    "\n",
    "model.build_vocab(sents, progress_per=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train & save the model\n",
    "model.train(sents, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "model.save(f\"{corpusName}_W2V_{windowsCount}_{minCount}_{workersCount}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7497167"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('horrendous', 'horrible')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('decent', 0.7581295371055603),\n",
       " ('great', 0.7506219744682312),\n",
       " ('terrific', 0.6600396037101746),\n",
       " ('fantastic', 0.6587141156196594),\n",
       " ('bad', 0.6501237750053406),\n",
       " ('tasty', 0.62489253282547),\n",
       " ('nice', 0.6247112154960632),\n",
       " ('yummy', 0.5859358906745911),\n",
       " ('phenomenal', 0.58575040102005),\n",
       " ('awesome', 0.5789355635643005)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word(\"good\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
